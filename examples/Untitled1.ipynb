{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22179250-ffdd-4f27-99cd-a55c6002e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a6d399-0443-4e77-9da1-f694531a1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_id = \"asst_4kcALVHNXPNWqNcAGl4m5nXa\"\n",
    "\n",
    "def run(thread_id):\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id, assistant_id=assistant_id\n",
    "    )\n",
    "    \n",
    "    messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "    \n",
    "    message_content = messages[0].content[0].text\n",
    "    annotations = message_content.annotations\n",
    "    citations = []\n",
    "    for index, annotation in enumerate(annotations):\n",
    "        message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "            cited_file = client.files.retrieve(file_citation.file_id)\n",
    "            citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "    \n",
    "    return message_content.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea9f27e-e764-465c-84a7-4c93c0caf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6d5b6af-2ffe-4236-9d6c-8ee137eb1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread.id,\n",
    "    role = \"user\",\n",
    "    content = \"What is 1 + 1?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fdbbbc0-c79e-4236-a5c1-e66aff044501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"result\": 2\\n}\\n```'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6883877-c36c-4827-b5ec-6a8f878638bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread.id,\n",
    "    role = \"user\",\n",
    "    content = \"Recite your last answer and also tell me what 4+3 is.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c62de43-c3a0-4094-99cb-b5a27d9fa116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"previous_answer\": \"1 + 1 is 2.\",\\n  \"result\": 7\\n}\\n```'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182bf8df-8fac-45b0-9aed-21f8303e3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e31c0b5-0a0e-4988-af83-348de8623711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_2WeDZPOlrHYcEaneZPCiccnB', assistant_id='asst_4kcALVHNXPNWqNcAGl4m5nXa', cancelled_at=None, completed_at=None, created_at=1727697246, expires_at=None, failed_at=1727697253, incomplete_details=None, instructions='You are a helpful assistant designed to output JSON.', last_error=LastError(code='rate_limit_exceeded', message='You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.'), max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1727697246, status='failed', thread_id='thread_lo74tU0WeGS4QAmH1OYhbEwZ', tool_choice='auto', tools=[FileSearchTool(type='file_search', file_search=FileSearch(max_num_results=None, ranking_options=FileSearchRankingOptions(score_threshold=0.0, ranker='default_2024_08_21')))], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0), temperature=1.0, top_p=1.0, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acf7da-b3b8-4ad3-9e6c-5dc2def54851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
